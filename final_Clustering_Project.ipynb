{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Poonam-github3011/Module6-Netflix-movies-and-Tv-shows/blob/main/final_Clustering_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  Unsupervised ML - Netflix Movies and TV Shows Clustering\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    -Unsupervised\n",
        "##### **Contribution**    - Team\n",
        "##### **Team Member 1 -** Poonam Khairnar\n",
        "##### **Team Member 2 -** Shreya Thorat\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project aims to analyze a Netflix dataset of movies and TV shows up to 2019 from Flixable, a third-party search engine. The objective is to group content using NLP techniques for a better user experience through a recommendation system, helping prevent Netflix subscriber churn among its 220 million users.\n",
        "\n",
        "> **This project started with** :\n",
        " * Handling null values in the dataset.\n",
        " * Managing nested columns for better visualization.\n",
        " * Categorizing ratings into groups (adult, children's, family-friendly, not rated).\n",
        " * Conducting Exploratory Data Analysis (EDA) to gain insights to better understand Dataset\n",
        " * Creating clusters using attributes like director, cast, country, genre, rating, and description, processed through TF-IDF vectorization.\n",
        " * Reducing dimensionality using PCA for improved performance.\n",
        " * Employing K-Means and Hierarchical Clustering algorithms, determining optimal clusters through various evaluation methods.\n",
        " * Developing a content-based recommender system with a cosine similarity matrix for personalized recommendations and reducing subscriber churn."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Poonam-github3011/Module6-Netflix-movies-and-Tv-shows"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement\n",
        "As one of the world's largest streaming platforms, Netflix offers a vast library of movies and TV shows. However, with so many options to choose from, it can be challenging for users to find content that matches their preferences.\n",
        "\n",
        "To address this challenge, this project aims to use unsupervised learning techniques to cluster similar movies and TV shows on Netflix. By grouping titles with similar attributes, we can provide users with more targeted recommendations, and help them find new content they will enjoy.\n",
        "\n",
        "Specifically, this project will involve analyzing a dataset of Netflix titles, including features such as genre, release year, cast, and plot summary, among others. By applying clustering algorithms such as K-Means or Hierarchical clustering, we aim to identify groups of movies and TV shows with similar attributes.\n",
        "\n",
        "Ultimately, the project aims to create a clustering model that can accurately group Netflix titles based on their characteristics. This model can then be used to make recommendations to users or to help Netflix improve its content discovery algorithms."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "## Data Maipulation Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "\n",
        "## Data Visualisation Libraray\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "# libraries used to process textual data\n",
        "import string\n",
        "string.punctuation\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# libraries used to implement clusters\n",
        "from sklearn.metrics import silhouette_score\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "import pickle\n",
        "\n",
        "# Library of warnings would assist in ignoring warnings issued\n",
        "import warnings;warnings.filterwarnings('ignore')\n",
        "import warnings;warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/Module6/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"
      ],
      "metadata": {
        "id": "mnUxxpH0RI9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "PSzsFAjjRhD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape\n"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of Rows: {df.shape[0]} \\nNumber of Columns: {df.shape[1]}\")"
      ],
      "metadata": {
        "id": "ifeTPUJgRmQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f\"Duplicate Value Counts: {df.duplicated().sum()}\")"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "null_counts = df.isnull().sum()\n",
        "\n",
        "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='mako')\n",
        "plt.title('Number of Null Values in Each Columns')\n",
        "plt.xlabel('Number of Null Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * The Netflix Movies and TV Shows Clustering dataset comprises information on TV shows and movies available on Netflix as of 2019. With 7787 entries and 12 columns, the dataset includes a mix of categorical and numerical variables.\n",
        "> * Some variables such as director, cast, country, date added, and rating contain null values."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='all').T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes.value_counts()"
      ],
      "metadata": {
        "id": "ukPch8tfSW7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "| Column         |              Description                                                           |\n",
        "|----------------|-----------------------------------------------------------------------|\n",
        "| **show_id**    | A unique identifier for each movie or TV show in the dataset.         |\n",
        "| **type**       | Indicates whether the entry is a movie or a TV show.                   |\n",
        "| **title**      | The title of the movie or TV show.                                    |\n",
        "| director       | The name of the director(s) associated with the content.              |\n",
        "| **cast**       | The names of the main cast members in the movie or TV show.           |\n",
        "| **country**    | The country or countries where the content was produced or originated.|\n",
        "| **date_added** | The date when the movie or TV show was added to Netflix.              |\n",
        "| **release_year**| The year when the movie or TV show was originally released.           |\n",
        "| **rating**     | The content rating assigned to the movie or TV show (e.g., PG, TV-MA).|\n",
        "| **duration**   | The duration of the movie or TV show (e.g., \"1h 30m\" for 1 hour and 30 minutes).|\n",
        "| **listed_in**  | The categories or genres in which the content is listed.              |\n",
        "| **description**| A brief summary or description of the movie or TV show.               |\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "def unique_values(data_frame):\n",
        "    for column in data_frame.columns:\n",
        "        unique_values = data_frame[column].nunique()\n",
        "        print(f\"Column '{column}' has  unique value(s): {unique_values}\")\n",
        "\n",
        "# Call the function with your DataFrame\n",
        "unique_values(df)"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of the dataframe before Data Wrangling\n",
        "print(f\"Dataset size before dropping values : {df.shape}\")"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.copy()"
      ],
      "metadata": {
        "id": "vG0IZyzqS_z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values for 'director', 'cast', and 'country' columns with 'Unknown'\n",
        "new_df[['director','cast','country']] = new_df[['director','cast','country']].fillna('Unknown')"
      ],
      "metadata": {
        "id": "kMjZG8iaTEHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values for 'rating' with the mode value\n",
        "new_df['rating']= new_df['rating'].fillna(new_df['rating'].mode()[0])"
      ],
      "metadata": {
        "id": "8lWBBgvtTIEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with any remaining missing values\n",
        "new_df.dropna(axis=0, inplace=True)"
      ],
      "metadata": {
        "id": "Wu7I8YAHTLXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['duration']=new_df['duration'].apply(lambda x: int(x.split()[0]))"
      ],
      "metadata": {
        "id": "WpIWgAqLTOmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of the dataframe after Data Wrangling\n",
        "print(f\"Dataset size after dropping  : {new_df.shape}\")"
      ],
      "metadata": {
        "id": "VZPpZwPfTQaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling nested columns"
      ],
      "metadata": {
        "id": "BDPqtou5TUrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = new_df.copy()"
      ],
      "metadata": {
        "id": "mg1vD_HATWTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unnest_column(df, column_name):\n",
        "    # Split the column and unnest\n",
        "    unnested_df = df[column_name].apply(lambda x: str(x).split(', ')).tolist()\n",
        "    df = pd.DataFrame(unnested_df, index=df['title']).stack()\n",
        "\n",
        "    # Create a DataFrame, reset the index, and set the column names\n",
        "    df = df.reset_index(level=1, drop=True).reset_index(name=column_name)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Applying the function for 'director', 'cast', 'listed_in', and 'country'\n",
        "dt1 = unnest_column(temp_df, 'director')\n",
        "dt2 = unnest_column(temp_df, 'cast')\n",
        "dt3 = unnest_column(temp_df, 'listed_in')\n",
        "dt4 = unnest_column(temp_df, 'country')"
      ],
      "metadata": {
        "id": "oRLBlbaQTZg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "3JeRQo64Tbl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging all together unnested dataframes"
      ],
      "metadata": {
        "id": "1HNpNRKGTetr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = (\n",
        "    dt2.merge(dt1, on='title', how='inner')\n",
        "       .merge(dt3, on='title', how='inner')\n",
        "       .merge(dt4, on='title', how='inner')\n",
        ")\n",
        "\n",
        "# Merging with the original DataFrame\n",
        "temp_df = dfs.merge(new_df[['type', 'title', 'date_added', 'release_year', 'rating', 'duration', 'description']],\n",
        "              on='title', how='left')"
      ],
      "metadata": {
        "id": "DSe1Pt5lTfk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.head()"
      ],
      "metadata": {
        "id": "KYcppWtGTjhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stripping leading and trailing white spaces from 'date_added' column\n",
        "temp_df['date_added'] = temp_df['date_added'].str.strip()\n",
        "\n",
        "# Typecasting string object to datetime object of date_added column\n",
        "temp_df['date_added'] = pd.to_datetime(temp_df['date_added'], format='%B %d, %Y')\n",
        "\n",
        "# Extracting date, day, month, and year from date_added column\n",
        "temp_df[\"day_added\"] = temp_df[\"date_added\"].dt.day\n",
        "temp_df[\"month_added\"] = temp_df[\"date_added\"].dt.month\n",
        "temp_df[\"year_added\"] = temp_df[\"date_added\"].dt.year\n",
        "\n",
        "# Dropping date_added\n",
        "temp_df.drop('date_added', axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "RoDw6B_gTpQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.info()"
      ],
      "metadata": {
        "id": "ViwUKSZWUS4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remaping ratings column  \n",
        "\n",
        "\n",
        "* **Adult Content** : TV-MA, NC-17, R\n",
        "* **Children Content** : TV-PG, PG, TV-G, G\n",
        "* **Teen Content** : PG-13, TV-14\n",
        "* **Family-friendly Content** : TV-Y, TV-Y7, TV-Y7-FV\n",
        "* **Not Rated** : NR, UR"
      ],
      "metadata": {
        "id": "UDHgmMZxUZEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binning the values in the rating column\n",
        "rating_map = {'TV-MA':'Adult Content',\n",
        "              'R':'Adult Content',\n",
        "              'PG-13':'Teen Content',\n",
        "              'TV-14':'Teen Content',\n",
        "              'TV-PG':'Children Content',\n",
        "              'NR':'Not Rated',\n",
        "              'TV-G':'Children Content',\n",
        "              'TV-Y':'Family-friendly Content',\n",
        "              'TV-Y7':'Family-friendly Content',\n",
        "              'PG':'Children Content',\n",
        "              'G':'Children Content',\n",
        "              'NC-17':'Adult Content',\n",
        "              'TV-Y7-FV':'Family-friendly Content',\n",
        "              'UR':'Not Rated'}\n",
        "\n",
        "new_df['rating'].replace(rating_map, inplace = True)\n",
        "new_df['rating'].unique()"
      ],
      "metadata": {
        "id": "LOqlDvVvUZ-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * Null values in the **'director'**, **'cast'**, and **'country'** columns have been filled with the string 'Unknown' using the fillna method.\n",
        "> * Null values in the **'rating'** column have been filled with the mode (most frequent value) of the column using the fillna method. Note that for **'rating'**, the inplace=True parameter has been used.\n",
        "> * The **'date_added'** column has been converted to datetime format using the pd.to_datetime method.\n",
        " * We have also extracted the following features:\n",
        "   *  'date' from 'date_added'.\n",
        "   *  'month' from 'date_added'.\n",
        "   *  'year' from 'date_added'.\n",
        "> * Rows containing any remaining missing values after the above manipulations have been dropped using the dropna method\n",
        "> * We have seen that the 'rating' column contains various coded categories, so we have decided to create 5 bins and distribute the values accordingly:\n",
        "  * **Adult** : TV-MA, NC-17\n",
        "  * **Restricted** : R, UR\n",
        "  * **Teen** : PG-13, TV-14\n",
        "  * **All Ages** : TV-G, TV-Y, TV-Y7, TV-Y7-FV, PG, G, TV-PG"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1: count of Movies vs TV Shows on Netflix."
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# count of Movies vs TV Shows on Netflix.\n",
        "\n",
        "\n",
        "# Creating the countplot to visualize the data\n",
        "plt.figure(figsize = (10,8))\n",
        "\n",
        "type_countplot = sns.countplot(data = new_df, x='type', palette='hot_r')\n",
        "\n",
        "# Adding  a title to the plot\n",
        "plt.title('Count of Movies vs TV Shows on Netflix', fontsize=15, color='black')\n",
        "\n",
        "# Adding count annotations on top of the bars\n",
        "for p in type_countplot.patches:\n",
        "    type_countplot.annotate(f'{p.get_height()}',\n",
        "                              (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                               ha='center', va='center', xytext=(0, 10),\n",
        "                                textcoords='offset points', fontsize=10, color='black')\n",
        "\n",
        "# Adding labels for the x and y axes\n",
        "plt.xlabel('Type', fontsize=12, color='black')\n",
        "plt.ylabel('Count', fontsize=12, color='black')\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot was chosen to visualize the distribution of movie and TV show types in the Netflix dataset due to its suitability for representing categorical data, enabling straightforward comparison of counts, and its simplicity, which facilitates clear communication of the distribution."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows there are more movies (5377) than TV shows (2400) in the Netflix dataset. Basically, Netflix has a lot more movies than TV shows."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * **Positive Impact**: Insights guide smart content decisions, optimizing Netflix's content strategy and tailoring user experiences for increased engagement.\n",
        "> * **Negative Impact**: Imbalances in content types may lead to dissatisfaction, highlighting the importance of diversification. Missing trend opportunities can result in a competitive disadvantage."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2: Distribution of release years of Netflix shows."
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Distribution of release years of Netflix shows.\n",
        "\n",
        "# Creating the histogram with Plotly\n",
        "release_year_hist = px.histogram(new_df, x='release_year', nbins=30, title='Distribution of Release Years of Netflix Shows',\n",
        "                                 labels={'release_year': 'Release Year'}, color_discrete_sequence=['red'],width=800, height=600,text_auto=True)\n",
        "\n",
        "# Updating layout\n",
        "release_year_hist.update_layout(\n",
        "    # Adding  a title to the plot\n",
        "    title=dict(text='Distribution of Release Years of Netflix Shows', x=0.5, y=0.95, xanchor='center', yanchor='top'),\n",
        "    # Adding labels for the x and y axes\n",
        "    xaxis=dict(title='Release Year', showgrid=True,title_font=dict(size=18)),\n",
        "    yaxis=dict(title='Count', showgrid=True,title_font=dict(size=18)),\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "# Displaying the plot\n",
        "release_year_hist.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histplot was chosen to show how many Netflix shows were released each year. It helps easily see trends, peaks, and gaps in the release history over the years, giving a clear picture of Netflix's content distribution."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * The chart highlights a spike in Netflix content production in 2015-2019, showcasing a recent emphasis on new releases.\n",
        "> * The distribution of content releases over time can reveal growth trends in Netflix's library. The chart shows an increasing trend in content releases over the years, it suggests that Netflix has been expanding its content library consistently."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the histogram of Netflix shows' release years can contribute to a positive business impact. Knowing when Netflix shows were released helps Netflix plan better. They can focus on the popular years, offer a variety of shows, and make decisions that match what viewers like. This can make users happier and more engaged with Netflix."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3:  Top 5 Countries in Netflix Shows"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "# Creating a pie chart with Plotly\n",
        "fig = px.pie(new_df['country'].value_counts().head(),\n",
        "             labels=new_df['country'].value_counts().head().index,\n",
        "             values=new_df['country'].value_counts().head().values,\n",
        "             title='Top 5 Countries in Netflix Shows',\n",
        "             names=new_df['country'].value_counts().head().index,\n",
        "             color_discrete_sequence=px.colors.qualitative.Set1,width=800, height=600)\n",
        "\n",
        "# Adding interactivity to the chart\n",
        "fig.update_layout(title=dict( x=0.5, y=0.95, xanchor='center', yanchor='top'))\n",
        "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "fig.update_layout(legend_title='Country')\n",
        "\n",
        "# Displaying the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This interactive pie chart allows to explore the distribution of shows among the top 5 countries with the highest number of shows. and can hover over the slices to see the country name, count, and percentage, providing a clear visualization of the relative proportions of shows in each country."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * The largest slice indicates that the United States has the highest number of shows, highlighting its significant contribution to Netflix's content library.\n",
        "> * Understanding the geographical distribution helps Netflix strategize content acquisition and production efforts to cater to diverse viewer preferences across different regions."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * **Strategic Decision-making**: Insights on dominant countries guide content strategies, enhancing viewer satisfaction and potential for increased viewership.\n",
        "> * **Competitor Analysis**: Assessing market share relative to other countries aids in understanding the competitive landscape, supporting strategic positioning."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4: Top 10 countries with the most Netflix shows"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "# Create a DataFrame with the top 10 countries\n",
        "top_countries = new_df['country'].value_counts().head(10).index\n",
        "\n",
        "# Filter data for the top 10 countries\n",
        "top_countries_data = new_df[new_df['country'].isin(top_countries)]\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.countplot(x='country', hue='type', order=top_countries, data=top_countries_data, palette='magma')\n",
        "\n",
        "# Add count annotations on top of the bars\n",
        "for p in plt.gca().patches:\n",
        "    plt.gca().annotate(f'{int(p.get_height())}',\n",
        "                 (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                 ha='center', va='center', xytext=(0, 10),\n",
        "                 textcoords='offset points', fontsize=10, color='black')\n",
        "\n",
        "# Adding a title to the plot\n",
        "plt.title('Top 10 Countries with Type Count on Netflix')\n",
        "# Adding labels for the x and y axes\n",
        "\n",
        "plt.xlabel('Count', fontsize=12, color='black')\n",
        "plt.ylabel('Country', fontsize=12, color='black')\n",
        "plt.legend(title='Type', loc='upper right')\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot is chosen for this task because it effectively visualizes the frequency count of each category (countries) on the x-axis and the count on the y-axis. This makes it easy to compare the distribution of movie and TV show counts across different countries in a clear and concise manner."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * The **United States** is a major contributor to Netflix, leading in both movies (1850) and TV shows (705), underscoring its significant influence on the platform's content.\n",
        "> * **India** stands out with a substantial movie count (852), but there's room for growth in TV shows (71), indicating a strong presence in movies.\n",
        "> * The **United Kingdom** maintains a balanced content output with comparable counts in both movies (193) and TV shows (204), reflecting a diverse content landscape."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * **Targeted Investment**: Insights guide strategic content investments, tailoring production to the influential U.S. market and recognizing growth potential in India.\n",
        "> * **Market expansion**: Identifying countries with a higher count of movies and TV shows can provide insights into potential markets for expansion. Netflix can prioritize expanding its presence in countries where there is already a substantial demand for their content."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 : Distribution of Content Ratings on Netflix"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# Distribution of Content Ratings on Netflix\n",
        "\n",
        "# Creating the countplot to visualize the data\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "rating_countplot = sns.countplot(data=new_df, x='rating', order=new_df['rating'].value_counts().index, color='skyblue')\n",
        "\n",
        "# Adding a title to the plot\n",
        "plt.title('Distribution of Content Ratings on Netflix', fontsize=15, color='black')\n",
        "\n",
        "# Adding labels for the x and y axes\n",
        "plt.xlabel('Rating', fontsize=12, color='black')\n",
        "plt.ylabel('Count', fontsize=12, color='black')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot is a suitable choice for visualizing the distribution to show how content ratings are distributed on Netflix. It's a good pick because it displays different ratings on the x-axis and shows how many times each rating appears on the y-axis. This makes it easy to see which ratings are more common and gives a quick overview of Netflix's content."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * Adult  and teen content ratings have the highest counts, indicating a significant presence of content suitable for mature audiences.\n",
        "> * Netflix offers content across a range of rated content, including childern, family-friendly  and others content, showcasing a diverse content library catering to various audience preferences."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * **Viewer Segmentation**: Knowledge of specific ratings' popularity helps in better understanding viewer segments. This segmentation can be leveraged for personalized recommendations and targeted marketing campaigns, improving user engagement.\n",
        "> * **Content Diversification**: Recognizing the diversity in ratings allows Netflix to continue offering a wide range of content suitable for different audiences. This diversification can attract a broader user base and enhance customer satisfaction."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6: Poplular genres on netflix"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Creating the countplot to visualize the data\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "df_genre = temp_df.groupby(['listed_in']).agg({'title': 'nunique'}).reset_index().sort_values(by=['title'], ascending=False)[:10]\n",
        "ax = sns.barplot(y=\"listed_in\", x='title', data=df_genre , palette = 'rocket')\n",
        "\n",
        "# Adding count annotations on top of the bars\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_width()}',\n",
        "                (p.get_width(), p.get_y() + p.get_height() / 2.),\n",
        "                ha='center', va='center', xytext=(18, 0), textcoords='offset points', fontsize=10, color='black')\n",
        "\n",
        "# Adding a title to the plot\n",
        "plt.title('Most Popular Genre on Netflix', fontsize=15, color='black')\n",
        "\n",
        "# Adding labels for the x and y axes\n",
        "plt.xlabel('Title Count', fontsize=12, color='black')\n",
        "plt.ylabel('Genre', fontsize=12, color='black')\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar plot is suitable for visualizing the count of unique titles in each genre on Netflix because it provides a clear representation of the distribution of titles across different genres."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * **\"International Movies\"** and **\"Dramas\"** are the most prevalent genres on Netflix, with a significantly higher count of unique titles.\n",
        "> * Genres like **\"Documentaries,\" \"Action & Adventure,\" and \"TV Dramas\"** have a notable presence, showcasing a diverse range of content available on Netflix."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * **Targeted Marketing**: Utilizing insights on popular genres enables Netflix to customize marketing campaigns, recommendations, and ads for specific viewer preferences, boosting the attraction and retention of subscribers.\n",
        "> * **Personalized Recommendations**: Genre insights enhance recommendation algorithms, allowing Netflix to offer more precise and personalized content suggestions, elevating the overall user experience."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 : Past 20 Years added Content on Netflix"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Counting the occurrences of each year in 'year_added'\n",
        "year_counts = temp_df['year_added'].value_counts().head(20).sort_index()\n",
        "\n",
        "# Creating a line plot to visualize the data\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.lineplot(x=year_counts.index, y=year_counts.values, marker='o')\n",
        "\n",
        "# Adding a title to the plot\n",
        "plt.title('Past 20 Years added Content on Netflix ', fontsize=15, color='black')\n",
        "\n",
        "# Adding grid and labels for the x and y axes\n",
        "plt.grid(True)\n",
        "plt.xlabel('Release Year', fontsize=12, color='black')\n",
        "plt.ylabel('Count', fontsize=12, color='black')\n",
        "\n",
        "# Displaying the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line chart is suitable for visualizing the distribution of Netflix content across different release years. It effectively shows the trend and variation in content production over time."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * A noticeable surge in content production is observed from 2016 onwards, reaching its peak in 2018. This period aligns with Netflix's strategic focus on original content creation and global expansion.\n",
        "> * The distribution of content releases over time can reveal growth trends in Netflix's library. The chart shows an increasing trend in content releases over the years, it suggests that Netflix has been expanding its content library consistently."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * **Content Strategy and Planning**: The insights from the line chart can inform Netflix's content strategy and planning. Understanding the historical trends in content production allows for more informed decisions on resource allocation, budgeting, and focus areas for future content creation.\n",
        "> * **Audience Engagement**: By analyzing the growth trends, Netflix can align content releases with periods of increased audience engagement. This strategic timing can maximize viewership, subscriber retention, and overall customer satisfaction."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 : Top actors performing in Movies and TV Shows"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "df_movies = temp_df[temp_df['type'] == 'Movie']\n",
        "df_tvshows = temp_df[temp_df['type'] == 'TV Show']\n",
        "\n",
        "plt.style.use('default')\n",
        "plt.figure(figsize=(18, 8))\n",
        "\n",
        "# Plotting Movies Actors\n",
        "plt.subplot(1, 2, 1)\n",
        "df_movies_actor = df_movies.groupby(['cast']).agg({'title':'nunique'}).reset_index().sort_values(by=['title'], ascending=False)[1:10]\n",
        "plot_movies = sns.barplot(y=\"cast\", x='title', data=df_movies_actor, palette='magma')\n",
        "plt.title('Top Actors in Movies')\n",
        "plt.xlabel('Number of Movies')\n",
        "\n",
        "\n",
        "# Adding count labels on the bars for Movies\n",
        "# Adjusting count value position for Movies\n",
        "for index, value in enumerate(df_movies_actor['title']):\n",
        "    plot_movies.text(value + 0.1, index, str(value), color='black', ha=\"left\", va=\"center\")\n",
        "\n",
        "\n",
        "# Plotting TV Shows Actors\n",
        "plt.subplot(1, 2, 2)\n",
        "df_tvshows_actor = df_tvshows.groupby(['cast']).agg({'title':'nunique'}).reset_index().sort_values(by=['title'], ascending=False)[1:10]\n",
        "plot_tvshows = sns.barplot(y=\"cast\", x='title', data=df_tvshows_actor, palette='magma')\n",
        "plt.title('Top Actors in TV Shows')\n",
        "plt.xlabel('Number of TV Shows')\n",
        "\n",
        "\n",
        "# Adding count labels on the bars for TV Shows\n",
        "for index, value in enumerate(df_tvshows_actor['title']):\n",
        "    plot_tvshows.text(value + 0.1, index, str(value), color='black', ha=\"left\", va=\"center\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This bar plot is suitable for visualizing the top actors in movies and TV shows because it effectively compares the number of appearances for each actor across the two categories"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * Anupam Kher leads with 41 appearances, establishing himself as the most prominent movie actor on Netflix.\n",
        "> * Bollywood influence is evident, with actors like Shah Rukh Khan, Naseeruddin Shah, and Akshay Kumar featuring prominently.\n",
        "> * Takahiro Sakurai dominates TV shows with 22 appearances, indicating a significant presence in this category.\n",
        "> * Japanese anime influence is observed through actors like Yuki Kaji, Ai Kayano, Daisuke Ono, and Junichi Suwabe.\n",
        "> * The contrast in top actors between movies and TV shows suggests diverse industry dynamics.\n",
        "> * Bollywood actors dominate movies, while Japanese anime-related content holds sway in TV shows."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * Netflix can strategically invest in movies or TV shows featuring highly popular actors, aligning with user preferences.\n",
        "> * Users are more likely to receive personalized recommendations based on their preferred actors, leading to increased user satisfaction.\n",
        "> * Popular actors can be leveraged in marketing and promotional campaigns to attract and retain subscribers."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 : What is the Distribution of Content Rating in each highest content creating countries?"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['rating'].replace(rating_map, inplace = True)"
      ],
      "metadata": {
        "id": "qlhMaNqSXZkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['count'] = 1\n",
        "data = temp_df.groupby('country')['count'].sum().sort_values(ascending=False).reset_index()[:10]\n",
        "top_countries = data['country']\n",
        "df_heatmap = temp_df[temp_df['country'].isin(top_countries)]\n",
        "df_heatmap = pd.crosstab(df_heatmap['country'], df_heatmap['rating'], normalize=\"index\").T\n",
        "\n",
        "# Plotting the heatmap\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
        "\n",
        "# Defining order of representation\n",
        "country_order = df_heatmap.columns\n",
        "rating_order = df_heatmap.index\n",
        "\n",
        "# Calling and plotting heatmap\n",
        "sns.heatmap(df_heatmap.loc[rating_order, country_order], square=True, linewidth=2.5, cbar=False, annot=True, fmt='1.0%',\n",
        "            vmax=.6, vmin=0.05, ax=ax, annot_kws={\"fontsize\": 12})\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The heatmap was chosen for its ability to visually represent the distribution of content ratings across different countries."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * We found that **most of the countries produces content related to Adult and Teen.**\n",
        "> * Amomg all the countries **INDIA has less content in Adult segment than teen content.**\n",
        "> * **85% of content is Adult content from spain.**\n",
        "> * **Canada produces more content related to Children and Family-Friendly content**."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> *Hypothetical Statement 1:*\n",
        "> * **Null Hypothesis**: There is no significant difference in the proportion ratings of drama movies and comedy movies on Netflix.\n",
        "> * **Alternative Hypothesis**: There is a significant difference in the proportion ratings of drama movies and comedy movies on Netflix.\n",
        "\n",
        "> *Hypothetical Statement 2:*\n",
        "> * **Null Hypothesis**: The average duration of TV shows added in the year 2020 on Netflix is not significantly different from the average duration of TV shows added in the year 2021.\n",
        "> * **Alternative Hypothesis**: The average duration of TV shows added in the year 2020 on Netflix is significantly different from the average duration of TV shows added in the year 2021.\n",
        "\n",
        "> *Hypothetical Statement 3:*\n",
        "> * **Null Hypothesis**: The proportion of TV shows added on Netflix that are produced in the United States is not significantly different from the proportion of movies added on Netflix that are produced in the United States.\n",
        "> * **Alternative Hypothesis**: The proportion of TV shows added on Netflix that are produced in the United States is significantly different from the proportion of movies added on Netflix that are produced in the United States."
      ],
      "metadata": {
        "id": "HIWecKIYZ2pH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Null Hypothesis**: There is no significant difference in the proportion ratings of drama movies and comedy movies on Netflix.\n",
        "\n",
        "> **Alternative Hypothesis**: There is a significant difference in the proportion ratings of drama movies and comedy movies on Netflix."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Import necessary libraries\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Subset the data to only include drama and comedy movies\n",
        "subset = temp_df[temp_df['listed_in'].str.contains('Dramas') | temp_df['listed_in'].str.contains('Comedies')]\n",
        "\n",
        "# Calculate the proportion of drama and comedy movies\n",
        "drama_prop = len(subset[subset['listed_in'].str.contains('Dramas')]) / len(subset)\n",
        "comedy_prop = len(subset[subset['listed_in'].str.contains('Comedies')]) / len(subset)\n",
        "\n",
        "# Set up the parameters for the z-test\n",
        "count = [int(drama_prop * len(subset)), int(comedy_prop * len(subset))]\n",
        "nobs = [len(subset), len(subset)]\n",
        "alternative = 'two-sided'\n",
        "\n",
        "# Perform the z-test\n",
        "z_stat, p_value = proportions_ztest(count=count, nobs=nobs, alternative=alternative)\n",
        "print('z-statistic:', z_stat)\n",
        "print('p-value:', p_value)\n",
        "\n",
        "# Set the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the results of the z-test\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We conclude that there is a significant difference in the proportion ratings of drama movies and comedy movies on Netflix."
      ],
      "metadata": {
        "id": "kuZbnq9uaG9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test we have used to obtain the P-value is the z-test for proportions."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used a z-test for proportions because we wanted to compare the proportions of two types of movies (drama and comedy) in a sample. The test helps us figure out if the difference we see in the proportions is likely due to a real distinction or just random chance. It's like checking if the observed difference is big enough to be considered meaningful. The test looks at the probability of seeing such a difference if there was actually no difference in the entire population."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Null Hypothesis**: The average duration of TV shows added in the year 2020 on Netflix is not significantly different from the average duration of TV shows added in the year 2021.\n",
        "\n",
        "> **Alternative Hypothesis**: The average duration of TV shows added in the year 2020 on Netflix is significantly different from the average duration of TV shows added in the year 2021."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Import necessary libraries\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Create separate dataframes for TV shows in 2020 and 2021\n",
        "tv_2020 = temp_df[(temp_df['type'] == 'TV Show') & (temp_df['release_year'] == 2020)]\n",
        "tv_2021 = temp_df[(temp_df['type'] == 'TV Show') & (temp_df['release_year'] == 2021)]\n",
        "\n",
        "# Perform two-sample t-test\n",
        "t, p = ttest_ind(tv_2020['duration'].astype(int),\n",
        "                 tv_2021['duration'].astype(int), equal_var=False)\n",
        "\n",
        "# Print the results\n",
        "print('t-value:', t)\n",
        "print('p-value:', p)\n",
        "\n",
        "# Set the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the interpretation of the results\n",
        "if p < alpha:\n",
        "    print(\"Reject the null hypothesis.\")\n",
        "\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis.\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we conclude That average duration of TV shows added in 2020 on Netflix is significantly different from the average duration of TV shows added in 2021."
      ],
      "metadata": {
        "id": "IqjpfVLEaX1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test used to obtain the P-Value is a two-sample t-test."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used a two-sample t-test because we wanted to compare the average durations of two groups of TV shows: those added in 2020 and those added in 2021. The test helps us figure out if the difference in average durations is likely due to a real distinction or just random chance. We also assumed that the variability in durations between the two groups might not be the same, so we used a version of the t-test that doesn't assume equal variability."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Null Hypothesis**: The proportion of TV shows added on Netflix that are produced in the United States is not significantly different from the proportion of movies added on Netflix that are produced in the United States.\n",
        "\n",
        "> **Alternative Hypothesis**: The proportion of TV shows added on Netflix that are produced in the United States is significantly different from the proportion of movies added on Netflix that are produced in the United States."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import numpy as np\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Separate data into movies and TV shows\n",
        "df_movies = temp_df[temp_df['type'] == 'Movie']\n",
        "df_tvshows = temp_df[temp_df['type'] == 'TV Show']\n",
        "\n",
        "# Calculate the proportion of TV shows and movies from the United States\n",
        "tv_proportion = np.sum(df_tvshows['country'].str.contains('United States')) / len(df_tvshows)\n",
        "movie_proportion = np.sum(df_movies['country'].str.contains('United States')) / len(df_movies)\n",
        "\n",
        "# Set up the parameters for the z-test\n",
        "count = [int(tv_proportion * len(df_tvshows)), int(movie_proportion * len(df_movies))]\n",
        "nobs = [len(df_tvshows), len(df_movies)]\n",
        "alternative = 'two-sided'\n",
        "\n",
        "# Perform the z-test\n",
        "z_stat, p_value = proportions_ztest(count=count, nobs=nobs, alternative=alternative)\n",
        "print('z-statistic:', z_stat)\n",
        "print('p-value:', p_value)\n",
        "\n",
        "# Set the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the results of the z-test\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis.\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We conclude that the proportion of TV shows added on Netflix that are produced in the United States is significantly different from the proportion of movies added on Netflix that are produced in the United States."
      ],
      "metadata": {
        "id": "uMsEzt9saoUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test used to obtain P-Value is a two-sample proportion test."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used this statistical test because it's good for comparing two proportions. It helps us figure out if the difference between the proportions of TV shows and movies from the United States is likely just random chance or if there's a real distinction between them."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "temp_df.isna().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's move ahead, as we have already deleted with null/ missing values from our dataset"
      ],
      "metadata": {
        "id": "_FdxFU5zcMSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing values to handle in the given dataset"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # Outlier detector\n",
        "def Outlier_detector(data, feature, figsize=(10, 7), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (12,7))\n",
        "    kde: whether to the show density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a triangle will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins\n",
        "    ) if bins else sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram\n",
        "# @markdown # Outlier detector\n",
        "def Outlier_detector(data, feature, figsize=(10, 7), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (12,7))\n",
        "    kde: whether to the show density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n"
      ],
      "metadata": {
        "id": "Dmssj0VidKVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# Defining  empty lists for different Datatypes\n",
        "numeric_columns = []\n",
        "# Seprating columns and categorize based on data type\n",
        "for column in temp_df.columns:\n",
        "    if temp_df[column].dtype in ['float64', 'int64']:\n",
        "      numeric_columns.append(column)"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for variable in numeric_columns[:-1]:\n",
        "  Outlier_detector(temp_df,variable)"
      ],
      "metadata": {
        "id": "bTlybI8VcqCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}